{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862265ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n",
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I RKNN: [16:32:44.489] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [16:32:44.489] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [16:32:44.489] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [16:32:44.513] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "I RKNN: [16:32:44.582] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [16:32:44.583] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [16:32:44.583] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: Caffe, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [16:32:44.588] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "불러오기 완료: ./features_data.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkice/miniconda3/envs/pyside6rknn/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PySide6.QtWidgets import QApplication, QMainWindow, QWidget, \\\n",
    "    QLabel, QGridLayout, QScrollArea, QSizePolicy, QFileDialog, QMessageBox\n",
    "from PySide6.QtGui import QPixmap, QIcon, QImage, QPalette, QPainter, QPen, QColor\n",
    "from PySide6.QtCore import QThread, Signal, Qt, QEvent, QObject, Slot\n",
    "from PySide6 import QtCore\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from onvif_control import *\n",
    "\n",
    "from embeddings import Embeddings\n",
    "from ui_Face_Overlay import *\n",
    "from rknnlite.api import RKNNLite\n",
    "\n",
    "def extract_filename(file_path):\n",
    "    full_filename = os.path.basename(file_path)\n",
    "    filename_without_extension = os.path.splitext(full_filename)[0]\n",
    "    return filename_without_extension\n",
    "\n",
    "def read_jpg_files(directory):\n",
    "    jpg_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.lower().endswith('.jpg'):\n",
    "            jpg_files.append(os.path.join(directory, file))\n",
    "    return jpg_files\n",
    "\n",
    "def save_json(path, data):\n",
    "    \"\"\"\n",
    "    numpy.ndarray 타입의 feature를 list로 바꿔서 JSON 저장\n",
    "    \"\"\"\n",
    "    serializable_data = []\n",
    "    for item in data:\n",
    "        serializable_item = {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"feature\": item[\"feature\"].tolist() if isinstance(item[\"feature\"], np.ndarray) else item[\"feature\"]\n",
    "        }\n",
    "        serializable_data.append(serializable_item)\n",
    "    \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(serializable_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"저장 완료:\", path)\n",
    "\n",
    "def load_json(path):\n",
    "    \"\"\"\n",
    "    JSON을 불러온 후 list → numpy.ndarray 로 복원\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        loaded = json.load(f)\n",
    "    \n",
    "    for item in loaded:\n",
    "        item[\"feature\"] = np.array(item[\"feature\"])\n",
    "    print(\"불러오기 완료:\", path)\n",
    "    return loaded\n",
    "\n",
    "class VideoThread(QThread):\n",
    "    frame_update = Signal(np.ndarray)\n",
    "    face_update = Signal(np.ndarray)\n",
    "\n",
    "    def __init__(self, rtsp_url, resize_size=None, overlay_path=None, overlay_ok_path=None, overlay_size=None, crop_rect=None):\n",
    "        super().__init__()\n",
    "        self.rtsp_url = rtsp_url\n",
    "        self.resize_size = resize_size\n",
    "        self.overlay_path = overlay_path\n",
    "        self.overlay_ok_path = overlay_ok_path\n",
    "        self.overlay_size = overlay_size\n",
    "        self.crop_rect = crop_rect\n",
    "        #self.overlay_point = (60, 30)\n",
    "        self.overlay_point = (\n",
    "            int((self.crop_rect[2] - self.crop_rect[0]) / 2 - self.overlay_size[0] / 2),\n",
    "            int((self.crop_rect[3] - self.crop_rect[1]) / 2 - self.overlay_size[1] / 2)\n",
    "        )\n",
    "        self.running = True\n",
    "        self.embeddings = Embeddings('./RetinaFace_mobile320_i8_v2.3.2.rknn', './rk3588_mobilefacenet/mobilefacenet_v2.3.2.rknn')\n",
    "        self.embedder_ret = None\n",
    "        #self.process = False\n",
    "\n",
    "        overlay = Image.open(self.overlay_path).convert(\"RGBA\")\n",
    "        self.overlay_resized = overlay.resize(self.overlay_size)\n",
    "\n",
    "        overlay = Image.open(self.overlay_ok_path).convert(\"RGBA\")\n",
    "        self.overlay_ok_resized = overlay.resize(self.overlay_size)\n",
    "\n",
    "        self.face_check = False\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.rtsp_url)\n",
    "\n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            if self.resize_size:\n",
    "                frame = cv2.resize(frame, self.resize_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            if self.crop_rect:\n",
    "                x1, y1, x2, y2 = self.crop_rect\n",
    "                self.crop_frame = frame[y1:y2, x1:x2].copy()\n",
    "\n",
    "            #if overlay_resized is not None:\n",
    "            #    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).convert(\"RGBA\")\n",
    "            #    frame_pil.paste(overlay_resized, self.overlay_point, overlay_resized)\n",
    "            #    frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGBA2BGR)\n",
    "            retina_ret = self.embeddings.retinaface.get_faces(self.crop_frame)\n",
    "            \n",
    "            if not self.face_check:\n",
    "                self.embedder_ret = []\n",
    "                for face in retina_ret:\n",
    "                    if face['nose'][0] <= 220 and face['nose'][0] >= 175 and face['nose'][1] <= 220 and face['nose'][1] >= 175:                    \n",
    "                        embedding = self.embeddings.mobilefacenet.get_feat(face['face'])\n",
    "                        self.embedder_ret.append({'score': face['score'], 'embedding': embedding})\n",
    "                        self.face_check = True\n",
    "                        #self.process = True\n",
    "                        self.face_update.emit(face['face_crop'])\n",
    "                    else:\n",
    "                        self.face_check = False\n",
    "                    #print(f\"Nose: {face['nose'][0]}, {face['nose'][1]}, \")\n",
    "\n",
    "            self.frame_update.emit(self.crop_frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.wait()\n",
    "\n",
    "class MyWindow(QMainWindow, Ui_MainWindow) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.resize_size=(640, 360)\n",
    "        self.crop_rect=(140, 0, 500, 360)\n",
    "        self.overlay_size=(300, 300)\n",
    "        self.face_size=(128, 128)\n",
    "        self.images = read_jpg_files('./img')\n",
    "        self.setupUi(self)\n",
    "\n",
    "        # Thread 1 - 그림1\n",
    "        self.camera = VideoThread(\n",
    "            \"rtsp://darkice:sys3275423@192.168.0.166:554/stream2\",\n",
    "            resize_size=self.resize_size,\n",
    "            overlay_path=\"facial-recognition.png\",\n",
    "            overlay_ok_path=\"facial-recognition_ok.png\",\n",
    "            overlay_size=self.overlay_size,\n",
    "            #crop_rect=(0, 0, 640, 360)  # x1, y1, x2, y2\n",
    "            #crop_rect=(140, 0, 500, 360)\n",
    "            crop_rect=self.crop_rect\n",
    "        )\n",
    "        self.camera.frame_update.connect(self.update_overlay)\n",
    "        self.camera.face_update.connect(self.update_face)\n",
    "        if os.path.exists(\"./features_data.json\"):\n",
    "            self.features = load_json(\"./features_data.json\")\n",
    "        else:\n",
    "            self.features = []\n",
    "            for j in range(len(self.images)):\n",
    "                img2 = cv2.imread(self.images[j])\n",
    "                get_face2 = self.camera.embeddings.get_embeddings(img2)\n",
    "                personname = extract_filename(self.images[j])\n",
    "                for i in range(len(get_face2)):\n",
    "                    feature = get_face2[i]['embedding']\n",
    "                embedding = {'name' : personname, 'feature' : feature}\n",
    "                self.features.append(embedding)\n",
    "\n",
    "            save_json(\"./features_data.json\", self.features)\n",
    "        #with open(\"features_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        #    json.dump(self.features, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        camera_ip = '192.168.0.166'  # 카메라 IP 주소\n",
    "        camera_port = 2020  # 카메라 포트 번호\n",
    "        camera_user = 'darkice'  # 사용자 이름\n",
    "        camera_password = 'sys3275423'  # 비밀번호\n",
    "        self.cam = OnvifCamera(camera_ip, camera_port, camera_user, camera_password, './wsdl')\n",
    "        a = self.cam.absolute_move( 0, 0, 0, 1)\n",
    "        self.camera.start()\n",
    "\n",
    "    def update_overlay(self, frame):\n",
    "\n",
    "        if self.camera.overlay_path is not None:\n",
    "            frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).convert(\"RGBA\")\n",
    "            if self.camera.face_check:\n",
    "                frame_pil.paste(self.camera.overlay_ok_resized, self.camera.overlay_point, self.camera.overlay_ok_resized)\n",
    "                detect_list = []\n",
    "                for j in range(len(self.features)):\n",
    "                    feature2 = self.features[j]['feature']\n",
    "                    match, cosine_similarity = self.camera.embeddings.compare_face(self.camera.embedder_ret[0]['embedding'], feature2)\n",
    "                    #print( f'name: {self.features[j]['name']}, match: {match}, face_distances : {cosine_similarity[0]}'  )\n",
    "                    if match == True:\n",
    "                        detect_list.append([self.features[j]['name'],cosine_similarity ])\n",
    "\n",
    "                if len(detect_list)>0 :\n",
    "                    name = max(detect_list, key=lambda x: x[1])[0]\n",
    "                    self.lineEdit.setText(name)\n",
    "                else:\n",
    "                    self.lineEdit.setText(\"모름!!\")\n",
    "\n",
    "                self.camera.face_check = False\n",
    "            else:\n",
    "                frame_pil.paste(self.camera.overlay_resized, self.camera.overlay_point, self.camera.overlay_resized)\n",
    "                self.lineEdit.setText(\"모름!!\")\n",
    "\n",
    "            frame_overlay = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGBA2BGR)\n",
    "        else:\n",
    "            frame_overlay = frame\n",
    "\n",
    "        h, w, ch = frame_overlay.shape\n",
    "        qimg = QImage(frame_overlay.data, w, h, ch * w, QImage.Format_BGR888)\n",
    "        pix = QPixmap.fromImage(qimg).scaled(\n",
    "            self.label.width(), self.label.height(),\n",
    "            Qt.KeepAspectRatio, Qt.SmoothTransformation\n",
    "        )\n",
    "        self.label.setPixmap(pix)\n",
    "\n",
    "    def update_face(self, frame):\n",
    "        frame_face = cv2.resize(frame, self.face_size, interpolation=cv2.INTER_AREA)\n",
    "        h, w, ch = frame_face.shape\n",
    "        qimg = QImage(frame_face.data, w, h, ch * w, QImage.Format_BGR888)\n",
    "        pix = QPixmap.fromImage(qimg).scaled(\n",
    "            self.label_2.width(), self.label_2.height(),\n",
    "            Qt.KeepAspectRatio, Qt.SmoothTransformation\n",
    "        )\n",
    "        self.label_2.setPixmap(pix)\n",
    "\n",
    "    def save_button_clicked(self):\n",
    "        # Handle push button click event\n",
    "        #pass\n",
    "        print(\"Push button clicked\")\n",
    "        \n",
    "        name = self.lineEdit_2.text()  # 예: \"capture\"\n",
    "        base_path = \"./img/\"\n",
    "        ext = \".jpg\"\n",
    "\n",
    "        # 처음 시도할 파일명\n",
    "        save_path = os.path.join(base_path, name + ext)\n",
    "\n",
    "        # 파일이 존재하면 뒤에 _1, _2 ... 붙이기\n",
    "        counter = 0\n",
    "        while os.path.exists(save_path):\n",
    "            counter += 1\n",
    "            save_path = os.path.join(base_path, f\"{name}_{counter}{ext}\")\n",
    "            \n",
    "        cv2.imwrite(save_path, self.camera.crop_frame)\n",
    "        self.images.append(save_path)\n",
    "        #self.images = read_jpg_files('./img')\n",
    "        #img2 = cv2.imread(self.images[j])\n",
    "        get_face = self.camera.embeddings.get_embeddings(self.camera.crop_frame)\n",
    "        personname = extract_filename(save_path)\n",
    "        for i in range(len(get_face)):\n",
    "            feature = get_face[i]['embedding']\n",
    "        embedding = {'name' : personname, 'feature' : feature}\n",
    "        self.features.append(embedding)\n",
    "\n",
    "        save_json(\"./features_data.json\", self.features)\n",
    "\n",
    "    def up_button_clicked(self):\n",
    "        a = self.cam.relative_move( 0, -0.1, 0, 1)\n",
    "\n",
    "    def down_button_clicked(self):\n",
    "        a = self.cam.relative_move( 0, 0.1, 0, 1)\n",
    "\n",
    "    def right_button_clicked(self):\n",
    "        a = self.cam.relative_move( 0.05, 0, 0, 1)\n",
    "\n",
    "    def left_button_clicked(self):\n",
    "        a = self.cam.relative_move( -0.05, 0, 0, 1)\n",
    "\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.camera.stop()\n",
    "        event.accept()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    if not QApplication.instance():\n",
    "        app = QApplication(sys.argv)\n",
    "    else:\n",
    "        app = QApplication.instance()\n",
    "\n",
    "    myWindow = MyWindow() \n",
    "    myWindow.show()\n",
    "    sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8513bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료: data.json\n",
      "불러오기 완료: data.json\n",
      "[{'name': 'Alice', 'feature': array([1, 2, 3])}, {'name': 'Bob', 'feature': array([4, 5, 6])}]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def save_json(path, data):\n",
    "    \"\"\"\n",
    "    numpy.ndarray 타입의 feature를 list로 바꿔서 JSON 저장\n",
    "    \"\"\"\n",
    "    serializable_data = []\n",
    "    for item in data:\n",
    "        serializable_item = {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"feature\": item[\"feature\"].tolist() if isinstance(item[\"feature\"], np.ndarray) else item[\"feature\"]\n",
    "        }\n",
    "        serializable_data.append(serializable_item)\n",
    "    \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(serializable_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"저장 완료:\", path)\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    \"\"\"\n",
    "    JSON을 불러온 후 list → numpy.ndarray 로 복원\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        loaded = json.load(f)\n",
    "    \n",
    "    for item in loaded:\n",
    "        item[\"feature\"] = np.array(item[\"feature\"])\n",
    "    print(\"불러오기 완료:\", path)\n",
    "    return loaded\n",
    "\n",
    "\n",
    "# ---------------- 예제 사용 ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 예제 데이터\n",
    "    data = [\n",
    "        {\"name\": \"Alice\", \"feature\": np.array([1, 2, 3])},\n",
    "        {\"name\": \"Bob\",   \"feature\": np.array([4, 5, 6])}\n",
    "    ]\n",
    "    \n",
    "    # 저장\n",
    "    save_json(\"data.json\", data)\n",
    "    \n",
    "    # 불러오기\n",
    "    loaded_data = load_json(\"data.json\")\n",
    "    print(loaded_data)\n",
    "    print(type(loaded_data[0][\"feature\"]))  # numpy.ndarray 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f9d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(self, vec1, vec2):\n",
    "    \"\"\"\n",
    "    vec1: (1,128)\n",
    "    vec2: (1,128)\n",
    "    \"\"\"\n",
    "    # 벡터 정규화\n",
    "    v1 = vec1 / np.linalg.norm(vec1)\n",
    "    v2 = vec2 / np.linalg.norm(vec2)\n",
    "\n",
    "    # 내적 값 = cosine similarity\n",
    "    return float(np.dot(v1, v2.T))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyside6rknn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
